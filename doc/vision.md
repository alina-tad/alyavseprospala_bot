# Техническое видение проекта Alyavseprospala Bot

## Содержание

1. [Технологии](#1-технологии) - выбор стек технологий
2. [Принцип разработки](#2-принцип-разработки) - методология и подходы
3. [Структура проекта](#3-структура-проекта) - организация файлов и папок
4. [Архитектура проекта](#4-архитектура-проекта) - компоненты и их взаимодействие
5. [Модель данных](#5-модель-данных) - структуры данных
6. [Работа с LLM](#6-работа-с-llm) - интеграция и взаимодействие
7. [Мониторинг LLM](#7-мониторинг-llm) - отслеживание работы модели
8. [Сценарии работы](#8-сценарии-работы) - пользовательские сценарии
9. [Деплой](#9-деплой) - развертывание
10. [Подход к конфигурированию](#10-подход-к-конфигурированию) - настройки
11. [Подход к логгированию](#11-подход-к-логгированию) - логирование

---

## 1. Технологии

**Основной стек:**
- **Python 3.11+** + **aiogram** - Telegram бот
- **OpenRouter** - LLM провайдер
- **JSON** - хранение данных и конфигурации

**Инструменты:**
- **Docker** - деплой
- **uv** - зависимости
- **make** - автоматизация
- **pytest** - тестирование

**KISS принцип:** Минимум зависимостей, максимум простоты для быстрого MVP.

---

## 2. Принцип разработки

**MVP-first:** Базовый текстовый бот → улучшения

**Модульность:** Бот | LLM | Данные - независимые компоненты

**Итеративность:** Короткие циклы разработки и тестирования

**Минимализм:** Только необходимый функционал, чистый код

**Расширяемость:** Легкое добавление новых функций и изменение существующих

---

## 3. Структура проекта

```
cursor_dreams_bot/
├── main.py                 # Точка входа
├── pyproject.toml          # Зависимости и конфигурация
├── uv.lock                 # Фиксированные версии
├── .env                    # Переменные окружения (локально)
├── README.md               # Основная документация
├── prompts/
│   └── alyavseprospala_prompt.txt  # Системный промпт
├── src/
│   ├── __init__.py
│   ├── bot.py              # Telegram бот
│   ├── llm.py              # Работа с LLM (primary + fallbacks)
│   ├── config.py           # Конфигурация приложения
│   └── data_manager.py     # Работа с JSON данными
├── data/
│   └── conversations.json  # История диалогов
└── doc/
    ├── guides/
    │   └── botfather_guide.md
    ├── product_idea.md
    ├── tasklist.md
    ├── vision.md
    └── llm_doc.md
```

---

## 4. Архитектура проекта

**Основные компоненты:**
- **Telegram Bot** - обработка сообщений и команд
- **LLM Client** - взаимодействие с OpenRouter
- **Data Manager** - работа с JSON данными
- **Config Manager** - управление настройками

**Взаимодействие (схема блоков):**
```
Пользователь → Telegram Bot → LLM Client → OpenRouter
                ↓
            Data Manager → JSON файлы
```

---

## 5. Модель данных

**Пользователь:**
```json
{
  "user_id": "123456789",
  "username": "user_name",
  "created_at": "2024-01-01T00:00:00Z",
  "settings": {}
}
```

**Диалог:**
```json
{
  "session_id": "uuid",
  "user_id": "123456789",
  "messages": [
    {"role": "system", "content": "системный промпт", "timestamp": "..."},
    {"role": "user", "content": "текст", "timestamp": "..."},
    {"role": "assistant", "content": "ответ", "timestamp": "..."}
  ],
  "created_at": "2024-01-01T00:00:00Z"
}
```

---

## 6. Работа с LLM

**Интеграция с OpenRouter:**
- Использование OpenAI client для совместимости
- Поддержка различных моделей через единый API
- Обработка ошибок и retry логика

**Системный промпт:**
- Описание характера и стиля бота
- Примеры диалогов и интерпретаций
- Этические принципы и ограничения

**Контекст диалога:**
- Сохранение истории для контекста
- Очистка старых диалогов

**Пример функции:**
```python
async def get_llm_response(messages: list) -> str:
    """Получение ответа от LLM через OpenRouter"""
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=config.api_key)
    response = client.chat.completions.create(model="gpt-4", messages=messages)
    return response.choices[0].message.content
```

---

## 7. Мониторинг LLM

**Логирование запросов и ответов**

**Количество запросов в день**

**Простота:** JSON логи + базовые счетчики

---

## 8. Сценарии работы

**Основной сценарий:**
1. Пользователь отправляет описание сна (текст)
2. Бот задает уточняющие вопросы
3. Пользователь отвечает
4. Бот дает интерпретацию в авторском стиле

**Дополнительные сценарии:**
- Экспорт истории диалогов для админа
- Команды: 
  - /start - приветствие и готовность помочь в интерпретации снов
  - /clear - очистить историю диалога
  - /stop - остановить бота

---

## 9. Деплой

**Для развертывания бота используем простой и надежный подход:**

1. **Переменные окружения** - упаковка приложения в Docker контейнер
2. **Локальный запуск** - запуск Docker на локальной машине
3. **Простой процесс развертывания** - минимум шагов для запуска
4. **Управление зависимостями** - uv для быстрой установки пакетов

---

## 10. Подход к конфигурированию

**Единый источник конфигурации:** Все настройки в .env файле

**Простота управления:** API ключи, параметры LLM, системные промпты в одном месте

---

## 11. Подход к логгированию

**Логирование основных событий:** Отслеживание ключевых операций бота

**Структурированные уровни:** INFO, WARNING, ERROR для разных типов событий 